{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.stats import sigma_clip\n",
    "from astropy.stats import biweight_midvariance as bimv\n",
    "from astropy.stats import biweight_location as bil\n",
    "from astropy.table import Table\n",
    "from astropy.utils.data import get_pkg_data_filename\n",
    "from collections import Counter\n",
    "import glob\n",
    "from matplotlib import cm\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import operator\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from scipy.interpolate import splprep, splev\n",
    "import sys\n",
    "import time\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correction(file, correction, sigma=2, poly=6):\n",
    "    \n",
    "    '''This version creates a global variable that is a matrix of the final output values. These\n",
    "    can be called using the indicies of the IFU, and are given in chronological order'''\n",
    "    \n",
    "    '''This section creates the correction matricies that will be used later. Each matrix needs\n",
    "    to hold the correction for the same column on the science frames, and we only want to apply\n",
    "    the correction from the same IFU as the science frame. So, we create an array for both the\n",
    "    left- and right-hand IFUs, and in this array each spot corresponds to a row and column on\n",
    "    the CCD field, i.e. 045. This will allow us to pull the correct correction matrix for the\n",
    "    science frame, by matching the row and column, as well as side.'''\n",
    "    \n",
    "    w, h = 10, 10;\n",
    "    lcorrection_array = [[0 for x in range(w)] for y in range(h)]\n",
    "    rcorrection_array = [[0 for x in range(w)] for y in range(h)]\n",
    "    correction_list = dict()\n",
    "    correction_data = dict()\n",
    "    \n",
    "    for alpha in correction:\n",
    "        hdul = fits.open(alpha)\n",
    "        correction_list[alpha] = [str(hdul[0].header['IFUSLOT']),str(hdul[0].header['CCDPOS'])]\n",
    "        correction_data[alpha] = [hdul[0].data]\n",
    "        row = int(correction_list[alpha][0][-1])\n",
    "        column = int(correction_list[alpha][0][:-1])-1\n",
    "        side = correction_list[alpha][1]\n",
    "\n",
    "        correction_matrix = [[0 for x in range(correction_data[alpha][0].shape[1])] for y in range(correction_data[alpha][0].shape[0])]\n",
    "        corr = correction_data[alpha][0].T\n",
    "    \n",
    "        for beta in range(np.shape(corr)[0]):\n",
    "            ave = bil(corr[beta])\n",
    "            fix = corr[beta]/ave\n",
    "\n",
    "            for gamma in range(np.shape(corr)[1]):\n",
    "                if fix[gamma] < 0.01:\n",
    "                    fix[gamma] = 0\n",
    "                correction_matrix[gamma][beta] = fix[gamma]\n",
    "\n",
    "        if side=='L':\n",
    "            lcorrection_array[row][column] = correction_matrix\n",
    "        if side=='R':\n",
    "            rcorrection_array[row][column] = correction_matrix\n",
    "            \n",
    "    '''This section makes the list of times of observations of the files being used.'''\n",
    "    \n",
    "    global times\n",
    "    times = set([])\n",
    "    file_list = dict()\n",
    "    data_list = dict()   \n",
    "    \n",
    "    for delta in file:\n",
    "        hdul = fits.open(delta)\n",
    "        file_list[delta] = [str(hdul[0].header['IFUSLOT']),str(hdul[0].header['CCDPOS']),str(hdul[0].header['UT'])]\n",
    "        data_list[delta] = [hdul[0].data]\n",
    "        times.add(file_list[delta][2])\n",
    "        \n",
    "    times = sorted(times)\n",
    "            \n",
    "    global output_matrix\n",
    "    output_matrix = [[[0 for z in range(len(times))] for x in range(10)] for y in range(10)]\n",
    "    \n",
    "    '''This section actually calculates output.'''\n",
    "    \n",
    "    '''We start by creating blank matrices.'''\n",
    "    \n",
    "    for epsilon in times:    \n",
    "        w, h = 10, 10;\n",
    "        lmatrix = [[0 for x in range(w)] for y in range(h)]\n",
    "        rmatrix = [[0 for x in range(w)] for y in range(h)]\n",
    "        matrix = [[0 for x in range(w)] for y in range(h)]\n",
    "        \n",
    "        timestamp = list(enumerate(times))[times.index(epsilon)][0]\n",
    "        \n",
    "        for zeta in file_list:\n",
    "            row = int(file_list[zeta][0][-1])\n",
    "            column = int(file_list[zeta][0][:-1])-1\n",
    "            side = file_list[zeta][1]\n",
    "            time = file_list[zeta][2]\n",
    "            \n",
    "            '''We only continue if the time matches. Each file will be done, but to correlate\n",
    "            the correct ones together, they are sorted by time.'''\n",
    "            \n",
    "            if time==epsilon:\n",
    "                \n",
    "                '''Here is where we pull the correction matrix, which are stored by side, row, and\n",
    "                column, as explained in the first step of the program.'''\n",
    "                \n",
    "                if side=='L':\n",
    "                    correction_matrix = lcorrection_array[row][column]\n",
    "                if side=='R':\n",
    "                    correction_matrix = rcorrection_array[row][column]\n",
    "                \n",
    "                im = data_list[zeta][0]\n",
    "                im = im/correction_matrix\n",
    "                sc = sigma_clip(im)\n",
    "                medfilt = sp.signal.medfilt(sc)\n",
    "                medfilt = ma.masked_invalid(medfilt)\n",
    "                rows = ma.mean(medfilt,axis=1)\n",
    "                y = list(range(len(rows)))\n",
    "                medpoly = np.poly1d(np.polyfit(y,rows,poly))\n",
    "                flattened = rows - medpoly(y)\n",
    "                source = []\n",
    "                count = 0\n",
    "                \n",
    "                '''The data is flattened, in order to correctly indentify points that are errors.\n",
    "                Normal clipping would not take into account the natural differences in various\n",
    "                parts of the frame, and so might cut actual data and leave real errors. The\n",
    "                degree fit can be changed when running the code.'''\n",
    "\n",
    "                for eta in range(len(rows)):\n",
    "                    mean = bil(flattened)         \n",
    "                    sig = ma.std(flattened)\n",
    "                    los = ma.where(flattened[eta]>(mean+sigma*sig))[0]\n",
    "                    if los.size:\n",
    "                        source.append(eta)\n",
    "\n",
    "                rows_list = np.ndarray.tolist(rows)\n",
    "                \n",
    "                '''The ones marked as errors are removed from the data set.'''\n",
    "\n",
    "                for theta in source:\n",
    "                    del rows_list[(theta-count)]\n",
    "                    count = count+1\n",
    "\n",
    "                '''The average of the remaining rows is found, and added to the correct side\n",
    "                matrix.'''    \n",
    "                \n",
    "                out = bil(rows_list)\n",
    "                if out < 16:\n",
    "                    out = 0\n",
    "                if side=='L':\n",
    "                    lmatrix[row][column] = out\n",
    "                if side=='R':\n",
    "                    rmatrix[row][column] = out\n",
    "\n",
    "        '''The side matrices are averaged, for a final matrix. This is done for each time that\n",
    "        data was taken, as calculated by the list of times section.'''            \n",
    "                    \n",
    "        for iota in range(10):\n",
    "            for kappa in range(10):\n",
    "                matrix[iota][kappa] = np.round(np.mean([lmatrix[iota][kappa],rmatrix[iota][kappa]]))\n",
    "                #matrix[iota][kappa] = np.mean([lmatrix[iota][kappa],rmatrix[iota][kappa]])\n",
    "                output_matrix[iota][kappa][timestamp] = np.mean([lmatrix[iota][kappa],rmatrix[iota][kappa]])\n",
    "        \n",
    "        print(\"Time:\",epsilon)\n",
    "        print(np.matrix(matrix))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=glob.glob(\"Fep*.fits\")\n",
    "corrections = glob.glob('../../cal/20180219_011102/Femastertwi*.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/numpy/lib/function_base.py:3558: RuntimeWarning: Invalid value encountered in median\n",
      "  RuntimeWarning)\n",
      "/home/rfoster/.local/lib/python3.5/site-packages/astropy/stats/biweight.py:110: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  mask = (np.abs(u) >= 1)\n",
      "/home/rfoster/.local/lib/python3.5/site-packages/ipykernel_launcher.py:94: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/home/rfoster/.local/lib/python3.5/site-packages/ipykernel_launcher.py:94: RuntimeWarning: invalid value encountered in true_divide\n",
      "WARNING: Input data contains invalid values (NaNs or infs), which were automatically masked. [astropy.stats.sigma_clipping]\n",
      "/home/rfoster/.local/lib/python3.5/site-packages/astropy/stats/sigma_clipping.py:165: RuntimeWarning: invalid value encountered in greater\n",
      "  _filtered_data.mask |= _filtered_data > max_value\n",
      "/home/rfoster/.local/lib/python3.5/site-packages/astropy/stats/sigma_clipping.py:166: RuntimeWarning: invalid value encountered in less\n",
      "  _filtered_data.mask |= _filtered_data < min_value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 07:02:15.498\n",
      "[[   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   0.    0.  241.    0.    0.    0.    0.    0.  219.  234.]\n",
      " [   0.    0.  229.    0.    0.    0.  250.  219.  220.  184.]\n",
      " [   0.    0.    0.  218.    0.    0.    0.  213.  150.  196.]\n",
      " [   0.    0.    0.  225.    0.    0.    0.  220.  190.  189.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.]]\n",
      "\n",
      "Time: 07:13:18.880\n",
      "[[   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   0.    0.  265.    0.    0.    0.    0.    0.  239.  257.]\n",
      " [   0.    0.  249.    0.    0.    0.  272.  238.  242.  201.]\n",
      " [   0.    0.    0.  237.    0.    0.    0.  230.  164.  216.]\n",
      " [   0.    0.    0.  244.    0.    0.    0.  239.  206.  209.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.]]\n",
      "\n",
      "Time: 07:24:18.292\n",
      "[[   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   0.    0.  266.    0.    0.    0.    0.    0.  231.  252.]\n",
      " [   0.    0.  246.    0.    0.    0.  268.  236.  240.  197.]\n",
      " [   0.    0.    0.  232.    0.    0.    0.  223.  162.  212.]\n",
      " [   0.    0.    0.  239.    0.    0.    0.  235.  202.  204.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "correction(files,corrections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
